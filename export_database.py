#!/usr/bin/env python3
"""
Script para exportar todo o banco de dados em planilhas CSV
Exporta as tabelas: clientes, assinaturas e transacoes
"""

import os
import sys
import pandas as pd
from datetime import datetime
from sqlalchemy import text, create_engine
from sqlalchemy.exc import OperationalError
import logging

# Adiciona o diret√≥rio src ao path para importar os m√≥dulos
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from database.connection import get_session
from database.models import Cliente, Assinatura, Transacao

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_database_connection():
    """
    Testa diferentes configura√ß√µes de conex√£o com o banco
    """
    logger.info("üîç Testando conex√µes com o banco de dados...")
    
    # Lista de URLs de conex√£o para testar
    connection_urls = [
        # URL do .env
        os.getenv("DATABASE_URL", "postgresql://metrics_user:asdfghjkl@localhost:5432/metrics_db"),
        # URL para Docker
        "postgresql://metrics_user:asdfghjkl@db:5432/metrics_db",
        # URL alternativa local
        "postgresql://metrics_user:asdfghjkl@127.0.0.1:5432/metrics_db",
    ]
    
    for i, url in enumerate(connection_urls, 1):
        try:
            logger.info(f"   Teste {i}: {url.split('@')[1] if '@' in url else url}")
            engine = create_engine(url)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            logger.info(f"   ‚úÖ Conex√£o {i} bem-sucedida!")
            return url
        except Exception as e:
            logger.info(f"   ‚ùå Conex√£o {i} falhou: {str(e)[:100]}...")
    
    logger.error("‚ùå Nenhuma conex√£o funcionou!")
    return None

def get_working_session():
    """
    Obt√©m uma sess√£o funcional do banco de dados
    """
    # Primeiro tenta a conex√£o padr√£o
    try:
        session = get_session()
        # Testa a conex√£o
        session.execute(text("SELECT 1"))
        logger.info("‚úÖ Usando conex√£o padr√£o do projeto")
        return session
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Conex√£o padr√£o falhou: {str(e)[:100]}...")
        
        # Testa outras conex√µes
        working_url = test_database_connection()
        if working_url:
            try:
                engine = create_engine(working_url)
                from sqlalchemy.orm import sessionmaker
                SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
                session = SessionLocal()
                logger.info("‚úÖ Usando conex√£o alternativa")
                return session
            except Exception as e:
                logger.error(f"‚ùå Erro ao criar sess√£o alternativa: {str(e)}")
        
        raise Exception("N√£o foi poss√≠vel conectar ao banco de dados. Verifique se o PostgreSQL est√° rodando.")

def export_table_to_csv(session, model_class, output_dir, filename):
    """
    Exporta uma tabela espec√≠fica para CSV
    
    Args:
        session: Sess√£o do banco de dados
        model_class: Classe do modelo SQLAlchemy
        output_dir: Diret√≥rio de sa√≠da
        filename: Nome do arquivo CSV
    """
    try:
        # Busca todos os dados da tabela
        query = session.query(model_class)
        df = pd.read_sql(query.statement, session.bind)
        
        # Cria o diret√≥rio de sa√≠da se n√£o existir
        os.makedirs(output_dir, exist_ok=True)
        
        # Caminho completo do arquivo
        filepath = os.path.join(output_dir, filename)
        
        # Exporta para CSV
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        logger.info(f"‚úÖ Tabela {model_class.__tablename__} exportada: {filepath}")
        logger.info(f"   üìä Registros exportados: {len(df)}")
        
        return len(df)
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao exportar {model_class.__tablename__}: {str(e)}")
        return 0

def export_database_complete():
    """
    Exporta todo o banco de dados em planilhas CSV
    """
    logger.info("üöÄ Iniciando exporta√ß√£o completa do banco de dados...")
    
    # Cria diret√≥rio de sa√≠da com timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"dados_exportados_completos_{timestamp}"
    
    # Configura√ß√µes das tabelas para exportar
    tables_config = [
        {
            'model': Cliente,
            'filename': 'clientes.csv',
            'description': 'Tabela de clientes'
        },
        {
            'model': Assinatura,
            'filename': 'assinaturas.csv',
            'description': 'Tabela de assinaturas'
        },
        {
            'model': Transacao,
            'filename': 'transacoes.csv',
            'description': 'Tabela de transa√ß√µes'
        }
    ]
    
    total_records = 0
    session = None
    
    try:
        # Obt√©m sess√£o do banco
        session = get_working_session()
        logger.info("üîå Conectado ao banco de dados")
        
        # Exporta cada tabela
        for table_config in tables_config:
            logger.info(f"üìã Exportando {table_config['description']}...")
            
            records_count = export_table_to_csv(
                session=session,
                model_class=table_config['model'],
                output_dir=output_dir,
                filename=table_config['filename']
            )
            
            total_records += records_count
        
        # Cria arquivo de resumo
        create_summary_file(output_dir, total_records, timestamp)
        
        logger.info(f"üéâ Exporta√ß√£o conclu√≠da com sucesso!")
        logger.info(f"üìÅ Arquivos salvos em: {output_dir}")
        logger.info(f"üìä Total de registros exportados: {total_records}")
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante a exporta√ß√£o: {str(e)}")
        raise
        
    finally:
        if session:
            session.close()
            logger.info("üîå Conex√£o com banco fechada")

def create_summary_file(output_dir, total_records, timestamp):
    """
    Cria um arquivo de resumo da exporta√ß√£o
    """
    try:
        summary_content = f"""# Resumo da Exporta√ß√£o do Banco de Dados

**Data/Hora da Exporta√ß√£o:** {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}
**Timestamp:** {timestamp}
**Total de Registros Exportados:** {total_records:,}

## Tabelas Exportadas:

### 1. Clientes (clientes.csv)
- Informa√ß√µes b√°sicas dos clientes
- Campos: id, nome, email, documento, data_criacao

### 2. Assinaturas (assinaturas.csv)
- Dados das assinaturas dos clientes
- Campos: id, id_assinatura_origem, plataforma, cliente_id, produto_nome, nome_oferta, status, data_inicio, data_proxima_cobranca, data_cancelamento, data_expiracao_acesso, valor_mensal, valor_anual, ultima_atualizacao

### 3. Transa√ß√µes (transacoes.csv)
- Hist√≥rico de transa√ß√µes financeiras
- Campos: id, id_transacao_origem, assinatura_id, cliente_id, plataforma, status, valor, valor_liquido, valor_bruto, taxa_reembolso, metodo_pagamento, data_transacao, motivo_recusa, json_completo, tipo_recusa, produto_nome, nome_oferta

## Observa√ß√µes:
- Todos os arquivos est√£o em formato CSV com encoding UTF-8
- O campo 'json_completo' da tabela transa√ß√µes cont√©m dados adicionais em formato JSON
- Os relacionamentos entre tabelas s√£o mantidos atrav√©s dos campos de ID
"""
        
        summary_file = os.path.join(output_dir, "README_EXPORTACAO.md")
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_content)
            
        logger.info(f"üìù Arquivo de resumo criado: {summary_file}")
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar arquivo de resumo: {str(e)}")

def check_docker_status():
    """
    Verifica se o Docker est√° rodando e sugere comandos
    """
    logger.info("üê≥ Verificando status do Docker...")
    
    # Verifica se docker-compose.yml existe
    if os.path.exists("docker-compose.yml"):
        logger.info("üìÑ Arquivo docker-compose.yml encontrado")
        logger.info("üí° Para iniciar o banco via Docker, execute:")
        logger.info("   docker-compose up -d db")
        logger.info("   ou")
        logger.info("   docker-compose up -d")
    else:
        logger.info("üìÑ Arquivo docker-compose.yml n√£o encontrado")

def main():
    """
    Fun√ß√£o principal
    """
    try:
        export_database_complete()
        print("\n" + "="*60)
        print("‚úÖ EXPORTA√á√ÉO CONCLU√çDA COM SUCESSO!")
        print("="*60)
        
    except Exception as e:
        print(f"\n‚ùå ERRO NA EXPORTA√á√ÉO: {str(e)}")
        print("\n" + "="*60)
        print("üîß SOLU√á√ïES POSS√çVEIS:")
        print("="*60)
        print("1. üê≥ Se usando Docker:")
        print("   docker-compose up -d db")
        print("   docker-compose up -d")
        print()
        print("2. üñ•Ô∏è  Se PostgreSQL local:")
        print("   - Verifique se o PostgreSQL est√° rodando")
        print("   - Confirme usu√°rio/senha no arquivo .env")
        print()
        print("3. üîç Para diagn√≥stico:")
        print("   python check_database.py")
        print()
        check_docker_status()
        sys.exit(1)

if __name__ == "__main__":
    main()
